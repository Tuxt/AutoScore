Using TensorFlow backend.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking_1 (Masking)          (None, 100, 1)            0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 100, 1, 10)        500       
_________________________________________________________________
reshape_1 (Reshape)          (None, 100, 10)           0         
_________________________________________________________________
gru_1 (GRU)                  (None, 100, 256)          205056    
_________________________________________________________________
gru_2 (GRU)                  (None, 128)               147840    
_________________________________________________________________
dense_1 (Dense)              (None, 50)                6450      
=================================================================
Total params: 359,846
Trainable params: 359,846
Non-trainable params: 0
_________________________________________________________________
None
Train on 88945 samples, validate on 29648 samples
Epoch 1/10
Epoch 00000: loss improved from inf to 2.38018, saving model to weights004_GRU-256_GRU-128_10-embedding/000_2.3802_0.2636_2.1043_0.3366.hdf5
/home/tuxt/tfg/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
EPOCH: 0 
loss: 2.38018280742 		— val_loss: 2.10429750721 
acc: 0.263556130194 		— val_acc: 0.336616297895 
precision: 0.134161421221 	— val_precision: 0.148512015104 
recall: 0.137015302128 	— val_recall: 0.150697286596 
f-measure: 0.117194984367 	— val_f-measure: 0.126986828715
Epoch 2/10
Epoch 00001: loss improved from 2.38018 to 1.98916, saving model to weights004_GRU-256_GRU-128_10-embedding/001_1.9892_0.3639_1.9061_0.3890.hdf5
EPOCH: 1 
loss: 1.98915707548 		— val_loss: 1.90607918525 
acc: 0.363921524534 		— val_acc: 0.388963842418 
precision: 0.228676526433 	— val_precision: 0.236986989209 
recall: 0.176902488019 	— val_recall: 0.193947509303 
f-measure: 0.174909776512 	— val_f-measure: 0.191588729205
Epoch 3/10
Epoch 00002: loss improved from 1.98916 to 1.84481, saving model to weights004_GRU-256_GRU-128_10-embedding/002_1.8448_0.4046_1.8178_0.4110.hdf5
EPOCH: 2 
loss: 1.84481445779 		— val_loss: 1.81777716983 
acc: 0.404609590199 		— val_acc: 0.411022665947 
precision: 0.304803521524 	— val_precision: 0.289617628368 
recall: 0.191254777248 	— val_recall: 0.201338452941 
f-measure: 0.200657969984 	— val_f-measure: 0.211193637222
Epoch 4/10
Epoch 00003: loss improved from 1.84481 to 1.76229, saving model to weights004_GRU-256_GRU-128_10-embedding/003_1.7623_0.4289_1.7614_0.4295.hdf5
EPOCH: 3 
loss: 1.76228865319 		— val_loss: 1.76144757055 
acc: 0.428905503398 		— val_acc: 0.429506206152 
precision: 0.318746921012 	— val_precision: 0.31348608765 
recall: 0.212689598652 	— val_recall: 0.214685123444 
f-measure: 0.224194360907 	— val_f-measure: 0.22658948588
Epoch 5/10
Epoch 00004: loss improved from 1.76229 to 1.69408, saving model to weights004_GRU-256_GRU-128_10-embedding/004_1.6941_0.4515_1.7292_0.4424.hdf5
EPOCH: 4 
loss: 1.69407623399 		— val_loss: 1.72920941843 
acc: 0.451492495359 		— val_acc: 0.442424446843 
precision: 0.360268082473 	— val_precision: 0.307113383449 
recall: 0.248003119886 	— val_recall: 0.239460873312 
f-measure: 0.261559985952 	— val_f-measure: 0.24754436114
Epoch 6/10
Epoch 00005: loss improved from 1.69408 to 1.63229, saving model to weights004_GRU-256_GRU-128_10-embedding/005_1.6323_0.4687_1.7111_0.4463.hdf5
EPOCH: 5 
loss: 1.63228565947 		— val_loss: 1.71112777192 
acc: 0.468705379732 		— val_acc: 0.446269562871 
precision: 0.406770320487 	— val_precision: 0.311999695781 
recall: 0.264308391152 	— val_recall: 0.241321929578 
f-measure: 0.282502491238 	— val_f-measure: 0.252687048393
Epoch 7/10
Epoch 00006: loss improved from 1.63229 to 1.57138, saving model to weights004_GRU-256_GRU-128_10-embedding/006_1.5714_0.4907_1.6940_0.4545.hdf5
EPOCH: 6 
loss: 1.57137618889 		— val_loss: 1.69402236805 
acc: 0.490707740736 		— val_acc: 0.454499460335 
precision: 0.450943040034 	— val_precision: 0.332294117556 
recall: 0.278062896564 	— val_recall: 0.24865729429 
f-measure: 0.295329087595 	— val_f-measure: 0.260118611143
Epoch 8/10
Epoch 00007: loss improved from 1.57138 to 1.51110, saving model to weights004_GRU-256_GRU-128_10-embedding/007_1.5111_0.5097_1.6844_0.4615.hdf5
EPOCH: 7 
loss: 1.51109864258 		— val_loss: 1.68444042082 
acc: 0.50966327506 		— val_acc: 0.461515110631 
precision: 0.44863150949 	— val_precision: 0.369036513148 
recall: 0.291621226989 	— val_recall: 0.252948164067 
f-measure: 0.317977161461 	— val_f-measure: 0.273531256345
Epoch 9/10
Epoch 00008: loss improved from 1.51110 to 1.44639, saving model to weights004_GRU-256_GRU-128_10-embedding/008_1.4464_0.5347_1.6688_0.4683.hdf5
EPOCH: 8 
loss: 1.44639366607 		— val_loss: 1.6688227512 
acc: 0.534734948561 		— val_acc: 0.468294657312 
precision: 0.476282188352 	— val_precision: 0.352747033866 
recall: 0.293592174864 	— val_recall: 0.243244212637 
f-measure: 0.326506798364 	— val_f-measure: 0.264003769964
Epoch 10/10
Epoch 00009: loss improved from 1.44639 to 1.37900, saving model to weights004_GRU-256_GRU-128_10-embedding/009_1.3790_0.5558_1.6663_0.4731.hdf5
EPOCH: 9 
loss: 1.37900055185 		— val_loss: 1.66630150921 
acc: 0.555815391543 		— val_acc: 0.473050458716 
precision: 0.504259832778 	— val_precision: 0.341181888184 
recall: 0.355497058879 	— val_recall: 0.27246835955 
f-measure: 0.380098219314 	— val_f-measure: 0.287739055756
------------------------------
TRAIN DATA: ['loss', 'acc']
[1.2582402999247364, 0.59949406938345384]
------------------------------
VALIDATION DATA: ['loss', 'acc']
[1.6663015092056117, 0.47305045871559631]
------------------------------
TEST DATA: ['loss', 'acc']
[1.7083210249952958, 0.46544571486692321]
10 epochs in 5524.774739980698 seconds
